{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN with 2 generators and 1 Classifier ver6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajagopalmotivate/try1/blob/master/DCGAN_with_2_generators_and_1_Classifier_ver6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rAnqTx79-fqy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Average\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from google.colab import files\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SGq7fGFGiMCO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget \"https://github.com/rajagopalmotivate/DeepLearnIITMA1/blob/master/model2001s%20(1).h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RrUhSz3A-kxl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_dataold():\n",
        "    (X_train, _), (_, _) = mnist.load_data()\n",
        "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "    return X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rpNahgVZlr37",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_large_data():\n",
        "    (X_train1, _), (_, _) = mnist.load_data()\n",
        "    (X_train2, _), (_, _) = fashion_mnist.load_data()\n",
        "    \n",
        "    X_trainlarge = np.zeros([10000,56,56],dtype=np.uint8)\n",
        "    \n",
        "    for i in range(0, 100):\n",
        "      for j in range(0, 100):    \n",
        "          aimage1 = X_train2[i]\n",
        "          aimage2 = X_train2[j]\n",
        "          largeimage =  np.zeros([56,56],dtype=np.uint8)\n",
        "          largeimage[0:56, 0:56] = 40\n",
        "          largeimage[0:28, 0:28] = aimage2\n",
        "          largeimage[0:28, 28:56] = aimage1\n",
        "          X_trainlarge[i*100 + j] = largeimage\n",
        " \n",
        "    \n",
        "    fig=plt.figure(figsize=(16, 16))\n",
        "    for i in range(0, 10):\n",
        "      for j in range(0, 10):\n",
        "          fig.add_subplot(10, 10, i*10 + j +1)\n",
        "          plt.imshow(X_trainlarge[i*100 + j + 1000])\n",
        "    plt.show()\n",
        "    \n",
        "    print(X_train2.shape)\n",
        "    print(X_trainlarge.shape)\n",
        "    \n",
        "    plt.imshow(aimage1)\n",
        "    plt.show()  \n",
        " \n",
        "    plt.imshow(aimage2)\n",
        "    plt.show()\n",
        "    \n",
        "    plt.imshow(largeimage, interpolation='none')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "    X_trainlarge = (X_trainlarge.astype(np.float32) - 127.5) / 127.5\n",
        "    X_trainlarge = np.expand_dims(X_trainlarge, axis=3)\n",
        "\n",
        "\n",
        "    return X_trainlarge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qs4PdEq_nSwQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_trainlarge = load_large_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xYZYOyupQBef",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_databydatasetname(datasetname):\n",
        "  if (datasetname == 1):   \n",
        "    (X_train, _), (_, _) = mnist.load_data()\n",
        "  if (datasetname == 2):   \n",
        "    (X_train, _), (_, _) = fashion_mnist.load_data()\n",
        "  X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "  X_train = np.expand_dims(X_train, axis=3)\n",
        "  return X_train\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rAvcp76J-pFy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v5Gt1N1m_qkt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_generator(noise_shape=(100,)):\n",
        "    input = Input(noise_shape)\n",
        "    x = Dense(128 * 7 * 7, activation=\"relu\")(input)\n",
        "    x = Reshape((7, 7, 128))(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2D(128, kernel_size=3, padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = Conv2D(1, kernel_size=3, padding=\"same\")(x)\n",
        "    out = Activation(\"tanh\")(x)\n",
        "    model = Model(input, out)\n",
        "    print(\"-- Generator -- \")\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_1oltuAI8_x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_discriminator(img_shape):\n",
        "    input = Input(img_shape)\n",
        "    x =Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(input)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = ZeroPadding2D(padding=((0, 1), (0, 1)))(x)\n",
        "    x = (LeakyReLU(alpha=0.2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = Conv2D(256, kernel_size=3, strides=1, padding=\"same\")(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = Flatten()(x)\n",
        "    out = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(input, out)\n",
        "    print(\"-- Discriminator -- \")\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GKL8BKzNJDaG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(generator1, generator2, discriminator, combined, epochs=2000, batch_size=128, save_interval=50):\n",
        "\n",
        "    X_train = load_databydatasetname(2)\n",
        "\n",
        "    num_examples = X_train.shape[0]/10\n",
        "    num_batches = int(num_examples / float(batch_size))\n",
        "    print('Number of examples: ', num_examples)\n",
        "    print('Number of Batches: ', num_batches)\n",
        "    print('Number of epochs: ', epochs)\n",
        "\n",
        "    half_batch = int(batch_size / 2)\n",
        "\n",
        "    for epoch in range(epochs + 1):\n",
        "        for batch in range(num_batches):\n",
        "\n",
        "            # noise images for the batch\n",
        "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
        "            fake_images = generator1.predict(noise)\n",
        "            fake_labels = np.zeros((half_batch, 1))\n",
        "\n",
        "            # real images for batch\n",
        "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "            real_images = X_train[idx]\n",
        "            real_labels = np.ones((half_batch, 1))\n",
        "\n",
        "            # Train the discriminator (real classified as ones and generated as zeros)\n",
        "            d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "            d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "            # Train the generator\n",
        "            g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "            # Plot the progress\n",
        "            print(\"Epoch %d Batch %d/%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
        "                  (epoch,batch, num_batches, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "\n",
        "            if batch % 50 == 0:\n",
        "                save_imgs(generator1, epoch, batch)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YJM5g5gmJV3U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_imgs(generator, epoch, batch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "            axs[i, j].axis('off')\n",
        "            cnt += 1\n",
        "    ##fig.savefig(\"images/mnist_%d_%d.png\" % (epoch, batch))\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CtDdi8MOJbMw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_generator_model():\n",
        "\n",
        "    gen_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        " \n",
        "    generator = build_generator()\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=gen_optimizer)\n",
        "\n",
        "  \n",
        "    return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8njAstGKgHYk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_classifier_model():\n",
        "\n",
        "    disc_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "\n",
        "\n",
        "    discriminator = build_discriminator(img_shape=(28, 28, 1))\n",
        "    discriminator.compile(loss='binary_crossentropy',\n",
        "                               optimizer=disc_optimizer,\n",
        "                               metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    return  discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e3Gqkow-gdE4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_combined_model():\n",
        "\n",
        "    discriminatormymodel = build_classifier_model\n",
        "\n",
        "    generatormymodel = build_generator_model()\n",
        "   \n",
        "    optimizer1 = Adam(lr=0.0002, beta_1=0.5)\n",
        "\n",
        "\n",
        "    z = Input(shape=(100,))\n",
        "    img = generatormymodel(z)\n",
        "    discriminatormymodel.trainable = False\n",
        "    real = discriminatormymodel(img)\n",
        "    \n",
        "    combined = Model(z, real)\n",
        "    \n",
        "    combined.compile(loss='binary_crossentropy', optimizer=optimizer1)\n",
        "    return combined"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZxRNGN5NYhjz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getlastlayer(amodel):\n",
        "  for layer in amodel.layers:\n",
        "    layerlast = layer\n",
        "  print(layer)\n",
        "  print(layer.get_config())\n",
        "  print(layer.input)\n",
        "  print(layer.input_shape)\n",
        "  print(layer.output)\n",
        "  print('output shape of last is ')\n",
        "  print(layer.output_shape)\n",
        "  return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gbWNmAeiRtL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_models():\n",
        "\n",
        "    gen1_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "    gen2_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "    disc_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "\n",
        "\n",
        "    discriminator = build_discriminator(img_shape=(28, 28, 1))\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=disc_optimizer,  metrics=['accuracy'])\n",
        "\n",
        "    generator1 = build_generator()\n",
        "    \n",
        "    generator2 = build_generator()\n",
        "\n",
        "    z = Input(shape=(100,))\n",
        "    img1 = generator1(z)\n",
        "    img2 = generator2(z)\n",
        "    merged = Average(getlastlayer(img1).output, getlastlayer(img2).output)\n",
        "    discriminator.trainable = False\n",
        "    real = discriminator(merged)\n",
        "    combined = Model(z, real)\n",
        "    \n",
        "    combined.summary()\n",
        "    \n",
        "    generator1.compile(loss='binary_crossentropy', optimizer=gen1_optimizer)\n",
        "    generator2.compile(loss='binary_crossentropy', optimizer=gen2_optimizer)\n",
        "    \n",
        "    combined.compile(loss='binary_crossentropy', optimizer=gen_optimizer)\n",
        "    return generator, discriminator, combined"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5nZ8mImn1iQ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_modelsNEW():\n",
        "    z = Input(shape=(100,))\n",
        "    inputz = z\n",
        "    x = Dense(128 * 7 * 7, activation=\"relu\")(inputz)\n",
        "    x = Reshape((7, 7, 128))(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2D(128, kernel_size=3, padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = Conv2D(1, kernel_size=3, padding=\"same\")(x)\n",
        "    out = Activation(\"tanh\")(x)    \n",
        "    generator1 = Model(inputz, out)\n",
        "    \n",
        "    inputz2 = z\n",
        "    x1 = Dense(128 * 7 * 7, activation=\"relu\")(inputz2)\n",
        "    x1 = Reshape((7, 7, 128))(x1)\n",
        "    x1 = BatchNormalization(momentum=0.8)(x1)\n",
        "    x1 = UpSampling2D()(x1)\n",
        "    x1 = Conv2D(128, kernel_size=3, padding=\"same\")(x1)\n",
        "    x1 = Activation(\"relu\")(x1)\n",
        "    x1 = BatchNormalization(momentum=0.8)(x1)\n",
        "    x1 = UpSampling2D()(x1)\n",
        "    x1 = Conv2D(64, kernel_size=3, padding=\"same\")(x1)\n",
        "    x1 = Activation(\"relu\")(x1)\n",
        "    x1 = BatchNormalization(momentum=0.8)(x1)\n",
        "    x1 = Conv2D(1, kernel_size=3, padding=\"same\")(x1)\n",
        "    out1 = Activation(\"tanh\")(x1)    \n",
        "    generator2 = Model(inputz2, out1)\n",
        "    \n",
        "    \n",
        "    img1 = generator1(z)\n",
        "    img2 = generator2(z)\n",
        "    \n",
        "    \n",
        "    aoptimizer = Adam(lr=0.0002, beta_1=0.5)   \n",
        "    discriminator = build_discriminator(img_shape=(28, 28, 1))\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=aoptimizer,  metrics=['accuracy'])\n",
        "    \n",
        "  ##  models = [generator1, generator2]\n",
        "    models = [generator1]\n",
        "    outputs = [model.outputs[0] for model in models]\n",
        "    merged = Average()(outputs)\n",
        "    discriminator.trainable = False\n",
        "    real = discriminator(merged)\n",
        "    combined = Model(z, real)\n",
        "        \n",
        "    generator1.compile(loss='binary_crossentropy', optimizer=aoptimizer)\n",
        "    generator2.compile(loss='binary_crossentropy', optimizer=aoptimizer)  \n",
        "    combined.compile(loss='binary_crossentropy', optimizer=aoptimizer)\n",
        "    \n",
        "    return generator1, generator2, discriminator, combined ,  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dpOWpMc2JhEp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    generator1, generator2, discriminator, combined = build_modelsNEW()\n",
        "\n",
        "    train(generator1, generator2,  discriminator, combined, \n",
        "          epochs=1, batch_size=32, save_interval=1)\n",
        "    \n",
        "    \n",
        "    generator1.save('generator1.h5')\n",
        "    discriminator.save('discriminator1.h5')\n",
        "    combined.save('combined1.h5')\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uQh3JBvCXo1-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7v9-327UXirU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MId5cxFzXffW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95hx9xw8WMjl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('generator1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "70UK-x9BWVD0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('discriminator1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AxMf_fh4Wl57",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('combined1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2Epw8b-WyAr",
        "colab_type": "code",
        "outputId": "b036b338-2ad4-46cf-e3f6-4112cf741174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "generator1 = load_model('generator1.h5')\n",
        "discriminator1 = load_model('discriminator1.h5')\n",
        "combined1 = load_model('combined1.h5')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "  warnings.warn('Error in loading the saved optimizer '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ti9dWQStWya8",
        "colab_type": "code",
        "outputId": "dbef7b5b-af7f-4766-8e1d-b4e7bcc668b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "cell_type": "code",
      "source": [
        "train(generator1, discriminator1, combined1,\n",
        "          epochs=1, batch_size=32, save_interval=1)"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-194-ab970b90cb8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train(generator1, discriminator1, combined1,\n\u001b[0;32m----> 2\u001b[0;31m           epochs=1, batch_size=32, save_interval=1)\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: train() missing 1 required positional argument: 'combined'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "E6fZSBxTdfcN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOSHhozYWzIk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXkjAXYBJicH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ns5gJ1w9_wj7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "##encodermodel = build_generator()\n",
        "##encodermodel.summary()\n",
        "\n",
        "##noise = np.random.normal(0, 1, (50, 100))\n",
        "##fake_images = encodermodel.predict(noise)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iOtS2UU7AFhK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##encodermodel.predict(inputnoise)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}