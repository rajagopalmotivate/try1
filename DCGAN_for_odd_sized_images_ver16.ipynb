{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN for odd sized images ver16.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajagopalmotivate/try1/blob/master/DCGAN_for_odd_sized_images_ver16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "voUWbaWdiq5-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "this is ensemble of 2 identical G\n",
        "\n",
        "this step is to train each G seperately \n",
        "\n",
        "once each G generates meaniful results, then ensemble them\n",
        "\n",
        "the way to train seperate is \n",
        "1) seperate train and load weights \n",
        "2) train with Avg (same G)\n"
      ]
    },
    {
      "metadata": {
        "id": "da7-tS-Ass9Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "from keras.utils import plot_model\n",
        "# Install dependencies\n",
        "!apt install graphviz\n",
        "!pip install pydot pydot-ng\n",
        "!echo \"Double check with Python 3\"\n",
        "!python -c \"import pydot\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PzSvsg3qgizZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "from keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_NawKScnOmYd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Restart runtime to allow Jupyter to know the changes above\n",
        "import os\n",
        "#os._exit(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rAnqTx79-fqy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Average, merge\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from google.colab import files\n",
        "import copy "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6pB5c2glOgoA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SGq7fGFGiMCO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RrUhSz3A-kxl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_dataold():\n",
        "    (X_train, _), (_, _) = fashion_mnist.load_data()\n",
        "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "    return X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rpNahgVZlr37",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_large_data():\n",
        "    (X_train1, _), (_, _) = mnist.load_data()\n",
        "    (X_train2, _), (_, _) = fashion_mnist.load_data()\n",
        "    \n",
        "    X_trainlarge = np.zeros([100000,28,56],dtype=np.uint8)\n",
        "    \n",
        "    for i in range(0, 100):\n",
        "      for j in range(0, 1000):    \n",
        "          aimage1 = X_train2[i]\n",
        "          aimage2 = X_train2[j]\n",
        "          largeimage =  np.zeros([28,56],dtype=np.uint8)\n",
        "          largeimage[0:28, 0:56] = 40\n",
        "          largeimage[0:28, 0:28] = aimage2\n",
        "          largeimage[0:28, 28:56] = aimage1\n",
        "          X_trainlarge[i*1000 + j] = largeimage\n",
        " \n",
        "    \n",
        "    fig=plt.figure(figsize=(16, 16))\n",
        "    for i in range(0, 10):\n",
        "      for j in range(0, 10):\n",
        "          fig.add_subplot(10, 10, i*10 + j +1)\n",
        "          plt.imshow(X_trainlarge[i*100 + j + 600])\n",
        "  ##plt.show()\n",
        "    \n",
        "    print(X_train2.shape)\n",
        "    print(X_trainlarge.shape)\n",
        "    \n",
        "    plt.imshow(aimage1)\n",
        "    plt.show()  \n",
        " \n",
        "    plt.imshow(aimage2)\n",
        "    plt.show()\n",
        "    \n",
        "    plt.imshow(largeimage, interpolation='none')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "    X_trainlarge = (X_trainlarge.astype(np.float32) - 127.5) / 127.5\n",
        "    X_trainlarge = np.expand_dims(X_trainlarge, axis=3)\n",
        "\n",
        "\n",
        "    return X_trainlarge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bTjq3QmOv2U-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_large_data5656():\n",
        "    (X_train1, _), (_, _) = mnist.load_data()\n",
        "    (X_train2, _), (_, _) = fashion_mnist.load_data()\n",
        "    \n",
        "    X_trainlarge = np.zeros([10000,56,56],dtype=np.uint8)\n",
        "    \n",
        "    for i in range(0, 100):\n",
        "      for j in range(0, 100):    \n",
        "          aimage1 = X_train2[i]\n",
        "          aimage2 = X_train2[j]\n",
        "          largeimage =  np.zeros([56,56],dtype=np.uint8)\n",
        "          largeimage[0:28, 0:56] = 40\n",
        "          largeimage[0:28, 0:28] = aimage2\n",
        "          largeimage[0:28, 28:56] = aimage1\n",
        "          X_trainlarge[i*100 + j] = largeimage\n",
        " \n",
        "    \n",
        "    fig=plt.figure(figsize=(16, 16))\n",
        "    for i in range(0, 10):\n",
        "      for j in range(0, 10):\n",
        "          fig.add_subplot(10, 10, i*10 + j +1)\n",
        "          plt.imshow(X_trainlarge[i*100 + j + 1000])\n",
        "  ##plt.show()\n",
        "    \n",
        "    print(X_train2.shape)\n",
        "    print(X_trainlarge.shape)\n",
        "    \n",
        "    plt.imshow(aimage1)\n",
        "    plt.show()  \n",
        " \n",
        "    plt.imshow(aimage2)\n",
        "    plt.show()\n",
        "    \n",
        "    plt.imshow(largeimage, interpolation='none')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "    X_trainlarge = (X_trainlarge.astype(np.float32) - 127.5) / 127.5\n",
        "    X_trainlarge = np.expand_dims(X_trainlarge, axis=3)\n",
        "\n",
        "\n",
        "    return X_trainlarge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qs4PdEq_nSwQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_trainlarge = load_large_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gC1tdA1ewP2Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_trainlarge5656 = load_large_data5656()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xYZYOyupQBef",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_databydatasetname(datasetname):\n",
        "  if (datasetname == 1):   \n",
        "    (X_train, _), (_, _) = mnist.load_data()\n",
        "  if (datasetname == 2):   \n",
        "    (X_train, _), (_, _) = fashion_mnist.load_data()\n",
        "  if (datasetname == 3):   \n",
        "     X_train = X_trainlarge\n",
        "  if (datasetname == 4):   \n",
        "     X_train = X_trainlarge5656\n",
        "\n",
        "  X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "  X_train = np.expand_dims(X_train, axis=3)\n",
        "  return X_train\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rAvcp76J-pFy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v5Gt1N1m_qkt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_generator(noise_shape=(100,)):\n",
        "    input = Input(noise_shape)\n",
        "    x = Dense(128 * 7 * 7, activation=\"relu\")(input)\n",
        "    x = Reshape((7, 7, 128))(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2D(128, kernel_size=3, padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = Conv2D(1, kernel_size=3, padding=\"same\")(x)\n",
        "    out = Activation(\"tanh\")(x)\n",
        "    model = Model(input, out)\n",
        "    print(\"-- Generator -- \")\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_1oltuAI8_x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_discriminator(img_shape):\n",
        "    input = Input(img_shape)\n",
        "    x =Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(input)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = ZeroPadding2D(padding=((0, 1), (0, 1)))(x)\n",
        "    x = (LeakyReLU(alpha=0.2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = Conv2D(256, kernel_size=3, strides=1, padding=\"same\")(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = Flatten()(x)\n",
        "    out = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(input, out)\n",
        "  #  print(\"-- Discriminator -- \")\n",
        "   # model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IdltwEwQ-ffa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_discriminator2856(img_shape):\n",
        "    input = Input(img_shape)\n",
        "    x =Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(input)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = ZeroPadding2D(padding=((0, 1), (0, 1)))(x)\n",
        "    x = (LeakyReLU(alpha=0.2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = Conv2D(256, kernel_size=3, strides=1, padding=\"same\")(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = Flatten()(x)\n",
        "    out = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(input, out)\n",
        "    print(\"-- Discriminator -- \")\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YJM5g5gmJV3U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_imgs(generator, epoch, batch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "            axs[i, j].axis('off')\n",
        "            cnt += 1\n",
        "    ##fig.savefig(\"images/mnist_%d_%d.png\" % (epoch, batch))\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CtDdi8MOJbMw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_generator_model():\n",
        "\n",
        "    gen_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        " \n",
        "    generator = build_generator()\n",
        "    generator.compile(loss='binary_crossentropy', optimizer=gen_optimizer)\n",
        "\n",
        "  \n",
        "    return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EMOBzvCAsaNQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def plotamodel(amodel, showdetails=True):\n",
        "  # Model summary\n",
        "  print(amodel.summary())\n",
        "\n",
        "  if (showdetails==True):\n",
        "    # Plot model graph\n",
        "    plot_model(amodel, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "    #Image(retina=True, filename='model.png')\n",
        "  if (showdetails==False):\n",
        "    # Plot model graph\n",
        "    plot_model(amodel, show_shapes=False, show_layer_names=False, to_file='modelsmall.png')\n",
        "   # Image(retina=True, filename='modelsmall.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8njAstGKgHYk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_classifier_model():\n",
        "\n",
        "    disc_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "\n",
        "\n",
        "    discriminator = build_discriminator(img_shape=(28, 28, 1))\n",
        "    discriminator.compile(loss='binary_crossentropy',\n",
        "                               optimizer=disc_optimizer,\n",
        "                               metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    return  discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GKL8BKzNJDaG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(generator1, generator2, discriminator, combined, mergedmodel,  epochs=2000, batch_size=128, save_interval=50, modeltotrain=1):\n",
        "\n",
        "    X_train = load_databydatasetname(2)\n",
        "    X_train5656 = None\n",
        "    \n",
        "    if modeltotrain == 3:\n",
        "          X_train5656 = load_databydatasetname(3)\n",
        "\n",
        "    num_examples = X_train.shape[0]\n",
        "    num_batches = int(num_examples / float(batch_size))\n",
        "    print('Number of examples: ', num_examples)\n",
        "    print('Number of Batches: ', num_batches)\n",
        "    print('Number of epochs: ', epochs)\n",
        "\n",
        "    half_batch = int(batch_size / 2)\n",
        "    ##quater_batch = int(half_batch / 2) \n",
        "\n",
        "    for epoch in range(epochs + 1):\n",
        "        for batch in range(num_batches):\n",
        "\n",
        "            # noise images for the batch\n",
        "            noise1 = np.random.normal(0, 1, (half_batch, 100))\n",
        "            fake_images1 = generator1.predict(noise1)\n",
        "            fake_labels1 = np.zeros((half_batch, 1))\n",
        "            \n",
        "           ## noise2 = np.random.normal(0, 1, (half_batch, 100))\n",
        "            noise2 = copy.deepcopy(noise1)\n",
        "            fake_images2 = generator2.predict(noise2)\n",
        "            fake_labels2 = np.zeros((half_batch, 1))\n",
        "            \n",
        "        \n",
        "            \n",
        "           ## fake_images = np.append(fake_images1 , fake_images2, axis=0)\n",
        "           ## fake_labels = np.append( fake_labels1 , fake_labels2, axis=0)\n",
        "            \n",
        "            if modeltotrain == 1:\n",
        "              fake_images = fake_images1\n",
        "              fake_labels = fake_labels1\n",
        "            if modeltotrain == 2:\n",
        "              fake_images = fake_images2\n",
        "              fake_labels = fake_labels2\n",
        "            if modeltotrain == 3:\n",
        "              noise2 = copy.deepcopy(noise1)\n",
        "              fake_images3 = mergedmodel.predict(noise2)\n",
        "              fake_labels3 = np.zeros((half_batch, 1))    \n",
        "              fake_images = fake_images3\n",
        "              fake_labels = fake_labels3              \n",
        "            \n",
        "            if(batch == 0):\n",
        "              print(\"G1 output numpy array shape\")\n",
        "              print(fake_images1.shape)\n",
        "              print(\"G1+G2 appended numpy array shape\")\n",
        "              print(fake_images.shape)\n",
        "\n",
        "            X_train = X_trainlarge\n",
        "            # real images for batch\n",
        "            idx = np.random.randint(0, X_train.shape[0], half_batch)            \n",
        "            real_images = X_train[idx]\n",
        "            real_labels = np.ones((half_batch, 1))\n",
        "\n",
        "            # Train the discriminator (real classified as ones and generated as zeros)\n",
        "            d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "            d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "            # Train the generator\n",
        "            g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "            # Plot the progress\n",
        "            print(\"Epoch %d Batch %d/%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n",
        "                  (epoch,batch, num_batches, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "\n",
        "            if batch % 100 == 0:\n",
        "                 save_imgs(generator1, epoch, batch)\n",
        "            if batch % 101 == 0:\n",
        "                 save_imgs(generator2, epoch, batch)\n",
        "            if batch % 102 == 0:\n",
        "                 save_imgs(mergedmodel, epoch, batch)\n",
        "                \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e3Gqkow-gdE4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_combined_model():\n",
        "\n",
        "    discriminatormymodel = build_classifier_model\n",
        "\n",
        "    generatormymodel = build_generator_model()\n",
        "   \n",
        "    optimizer1 = Adam(lr=0.0002, beta_1=0.5)\n",
        "\n",
        "\n",
        "    z = Input(shape=(100,))\n",
        "    img = generatormymodel(z)\n",
        "    discriminatormymodel.trainable = False\n",
        "    real = discriminatormymodel(img)\n",
        "    \n",
        "    combined = Model(z, real)\n",
        "    \n",
        "    combined.compile(loss='binary_crossentropy', optimizer=optimizer1)\n",
        "    return combined"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZxRNGN5NYhjz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getlastlayer(amodel):\n",
        "  for layer in amodel.layers:\n",
        "    layerlast = layer\n",
        "  print(layer)\n",
        "  print(layer.get_config())\n",
        "  print(layer.input)\n",
        "  print(layer.input_shape)\n",
        "  print(layer.output)\n",
        "  print('output shape of last is ')\n",
        "  print(layer.output_shape)\n",
        "  return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gbWNmAeiRtL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_models():\n",
        "\n",
        "    gen1_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "    gen2_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "    disc_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "\n",
        "\n",
        "    discriminator = build_discriminator(img_shape=(28, 28, 1))\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=disc_optimizer,  metrics=['accuracy'])\n",
        "\n",
        "    generator1 = build_generator()\n",
        "    \n",
        "    generator2 = build_generator()\n",
        "\n",
        "    z = Input(shape=(100,))\n",
        "    img1 = generator1(z)\n",
        "    img2 = generator2(z)\n",
        "    merged = Average(getlastlayer(img1).output, getlastlayer(img2).output)\n",
        "    \n",
        "    mergedmodel = Model(z, merged)\n",
        "    \n",
        "    discriminator.trainable = False\n",
        "    real = discriminator(merged)\n",
        "    combined = Model(z, real)\n",
        "    \n",
        "    combined.summary()\n",
        "    \n",
        "    generator1.compile(loss='binary_crossentropy', optimizer=gen1_optimizer)\n",
        "    generator2.compile(loss='binary_crossentropy', optimizer=gen2_optimizer)\n",
        "    \n",
        "    combined.compile(loss='binary_crossentropy', optimizer=gen_optimizer)\n",
        "    return generator, discriminator, combined, mergedmodel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5nZ8mImn1iQ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_modelsNandriNEW(averagemode = 1, loadpretrainedweights=False):\n",
        "    z = Input(shape=(100,))\n",
        "    inputz = z\n",
        "    x = Dense(128 * 7 * 7, activation=\"relu\")(inputz)\n",
        "    x = Reshape((7, 7, 128))(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2D(128, kernel_size=3, padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = Conv2D(1, kernel_size=3, padding=\"same\")(x)\n",
        "    out = Activation(\"tanh\")(x)    \n",
        "    generator1 = Model(inputz, out)\n",
        "    \n",
        "    inputz2 = z\n",
        "    x1 = Dense(128 * 7 * 7, activation=\"relu\")(inputz2)\n",
        "    x1 = Reshape((7, 7, 128))(x1)\n",
        "    x1 = BatchNormalization(momentum=0.8)(x1)\n",
        "    x1 = UpSampling2D()(x1)\n",
        "    x1 = Conv2D(128, kernel_size=3, padding=\"same\")(x1)\n",
        "    x1 = Activation(\"relu\")(x1)\n",
        "    x1 = BatchNormalization(momentum=0.8)(x1)\n",
        "    x1 = UpSampling2D()(x1)\n",
        "    x1 = Conv2D(64, kernel_size=3, padding=\"same\")(x1)\n",
        "    x1 = Activation(\"relu\")(x1)\n",
        "    x1 = BatchNormalization(momentum=0.8)(x1)\n",
        "    x1 = Conv2D(1, kernel_size=3, padding=\"same\")(x1)\n",
        "    out1 = Activation(\"tanh\")(x1)    \n",
        "    generator2 = Model(inputz2, out1)\n",
        "    \n",
        "    \n",
        "    img1 = generator1(z)\n",
        "    img2 = generator2(z)\n",
        "    \n",
        "    \n",
        "    aoptimizer = Adam(lr=0.0002, beta_1=0.5)   \n",
        "    discriminator = build_discriminator(img_shape=(28, 56, 1))\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=aoptimizer,  metrics=['accuracy'])\n",
        "    \n",
        "    if(averagemode == 1):\n",
        "          models = [generator1, generator1]\n",
        "    if(averagemode == 2):\n",
        "          models = [generator2, generator2]\n",
        "    if(averagemode == 3):\n",
        "          models = [generator1, generator2]\n",
        "\n",
        "\n",
        "  ##  models = [generator1, generator2]\n",
        " ##   models = [generator1, generator1]\n",
        "    outputs = [model.outputs[0] for model in models]\n",
        "    for obj1 in outputs:\n",
        "      print(type(obj1))\n",
        "      print(obj1.shape)\n",
        "        \n",
        "    mergedlayer = Concatenate(axis=2)(outputs)\n",
        "    ##x = merge([lstm_out, auxiliary_input], mode='concat')\n",
        "   ## output = merge([tower_1, tower_2, tower_3], mode='concat', concat_axis=1)\n",
        "  #  mergedlayer = merge([generator1, generator2], mode='concat', concat_axis=1)\n",
        "  \n",
        "   #mergedlayer = merge([out1, out], mode='concat', concat_axis=1)\n",
        "#contact axis can be -1 to 0 , 1 for inception , 2 , 3 or remove it\n",
        "  #  mergedlayer = merge([generator1, generator1])\n",
        "\n",
        "    print('merge layers')\n",
        "    print(out1.shape)\n",
        "    print(out.shape)\n",
        "    print(mergedlayer.shape)\n",
        "\n",
        "  \n",
        "\n",
        "    \n",
        "    \n",
        "    mergedmodel = Model(z, mergedlayer)\n",
        "    \n",
        "    discriminator.trainable = False\n",
        "    real = discriminator(mergedlayer)\n",
        "    combined = Model(z, real)\n",
        "        \n",
        "\n",
        "    \n",
        "    if(loadpretrainedweights==True):\n",
        "      generator1.load_weights('my_model_weights_mnist.h5')\n",
        "      generator2.load_weights('my_model_weights_mnist.h5')\n",
        "      #generator1 = load_model('generator2fmnist.h5')\n",
        "      #generator2 = load_model('generator2fmnist.h5')\n",
        "      \n",
        "\n",
        "    generator1.compile(loss='binary_crossentropy', optimizer=aoptimizer)\n",
        "    generator2.compile(loss='binary_crossentropy', optimizer=aoptimizer)  \n",
        "    combined.compile(loss='binary_crossentropy', optimizer=aoptimizer) \n",
        "  \n",
        "    plotamodel(mergedmodel)\n",
        "   # plotamodel(combined)\n",
        "    \n",
        "    return generator1, generator2, discriminator, combined ,  mergedmodel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dpOWpMc2JhEp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "generator1, generator2, discriminator, combined , mergedmodel = build_modelsNandriNEW( averagemode = 1 ,  loadpretrainedweights=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WbX8oGxBM9P4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/rajagopalmotivate/try1/raw/master/my_model_weights_mnist.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XbG-B4dgWp5g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plotamodel(combined)\n",
        "files.download('model.png')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CA1f1RWY9DOi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plotamodel(discriminator)\n",
        "files.download('model.png')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7v9-327UXirU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(generator1, generator2,  discriminator, combined, mergedmodel,  epochs=1, batch_size=32, save_interval=10, modeltotrain=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uQh3JBvCXo1-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(generator1, generator2,  discriminator, combined, mergedmodel,  epochs=4, batch_size=32, save_interval=10, modeltotrain = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_AKk3AmPN41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "generator1, generator2, discriminator, combined , mergedmodel = build_modelsNandriNEW( averagemode = 2 ,  loadpretrainedweights=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qJjUDNPKPO0L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(generator1, generator2,  discriminator, combined, mergedmodel,  epochs=1, batch_size=32, save_interval=1, modeltotrain = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FvrUh3I3YdBo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator1, generator2, discriminator, combined , mergedmodel = build_modelsNandriNEW( averagemode = 3 ,  loadpretrainedweights=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hc437ZsXZTNj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(generator1, generator2,  discriminator, combined, mergedmodel,  epochs=1, batch_size=64, save_interval=1, modeltotrain = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LYV-I4qWZUcY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(generator1, generator2,  discriminator, combined, mergedmodel,  epochs=4, batch_size=64, save_interval=1, modeltotrain = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vbQLbxLGimuS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plotamodel(combined, showdetails=False )\n",
        "files.download('modelsmall.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MId5cxFzXffW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf generator1fminst.h5\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEfSp4_Kmws_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "generator1.save('generator1fminst.h5')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iyGKz7dPjDun",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('generator1fminst.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eH6f7WOqtbL5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator1, generator2, discriminator, combined , mergedmodel = build_modelsNEW( averagemode = 2 ,  loadpretrainedweights=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zxa5bUVztmPv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(generator1, generator2,  discriminator, combined, mergedmodel,  epochs=1, batch_size=32, save_interval=20, modeltotrain=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XIV1w7zIjePT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf generator2fmnist.h5\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sRh_Q0q32eK9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "generator2.save('generator2fmnist.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o9FrEfY63DgT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -al\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KwiZz8Ne503l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('generator2fmnist.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ALMDD7eL5vC2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##!wget https://github.com/rajagopalmotivate/try1/raw/master/generatorTrainedepoch2git.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HWVzT10FntPz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf generator1fminst.h5\n",
        "!rm -rf generator2fminst.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RMQelKvAnwjl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KD8rcE9hnUkv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/rajagopalmotivate/try1/raw/master/generator1fminst.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Vaaz3qdaI0P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/rajagopalmotivate/try1/raw/master/generator2fminst.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M0UTSlz1nVET",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "56j8pW5Ltq7-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator1, generator2, discriminator, combined , mergedmodel = build_modelsNEW( averagemode = 3 ,  loadpretrainedweights=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "06G1wxTmpeM3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plotamodel(combined, showdetails=False )\n",
        "files.download('modelsmall.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DhZrYiA-pdtV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plotamodel(combined, showdetails=True )\n",
        "files.download('model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wOFpaL20tt73",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(generator1, generator2,  discriminator, combined, mergedmodel,  epochs=2, batch_size=32, save_interval=1, modeltotrain=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CfJDlXzcuKGd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(generator1, generator2,  discriminator, combined, mergedmodel,  epochs=2, batch_size=32, save_interval=1, modeltotrain=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9j7-errwEN0u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator1, generator2, discriminator, combined , mergedmodel = build_modelsNEW( averagemode = 3 ,  loadpretrainedweights=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ww38IVrHEONJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(generator1, generator2,  discriminator, combined, mergedmodel,  epochs=2, batch_size=32, save_interval=1, modeltotrain=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FUlds7hJHceo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(generator1, generator2,  discriminator, combined, mergedmodel,  epochs=2, batch_size=32, save_interval=1, modeltotrain=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YSUFwrSqJDkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plotamodel(combined)\n",
        "files.download('model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZmUpLdphH8Ud",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf generatorTrainedepoch2.h5\n",
        "\n",
        "generator1.save('generator1fminst.h5')\n",
        "\n",
        "!rm -rf generator2Trainedepoch2.h5\n",
        "\n",
        "generator2.save('generator2fminst.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VeuyouqTnO73",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-RI9MWbCnrey",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator1 = generator1.load_weights('generator1fmnist.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-3ki9iV8ny3C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator2 = generator2.load_weights('generator1fminst.h5')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gbL0SP9Vl0et",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(generator1, generator2,  discriminator, combined, mergedmodel,  epochs=2, batch_size=32, save_interval=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P2KJUo6Nl5ui",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator1.save('generatorTrained1epoch4.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95hx9xw8WMjl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('generator1fmnist.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cpnUVhqa5sjb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('generator2fmnist.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "70UK-x9BWVD0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##files.download('discriminator1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AxMf_fh4Wl57",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##files.download('combined1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2Epw8b-WyAr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#generator1 = load_model('generator1.h5')\n",
        "#discriminator1 = load_model('discriminator1.h5')\n",
        "#combined1 = load_model('combined1.h5')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ti9dWQStWya8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E6fZSBxTdfcN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOSHhozYWzIk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXkjAXYBJicH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ns5gJ1w9_wj7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iOtS2UU7AFhK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}